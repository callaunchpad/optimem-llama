{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baa15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# This software may be used and distributed according to the terms of the GNU General Public License version 3.\n",
    "\n",
    "from typing import Tuple\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from llama import ModelArgs, Transformer, Tokenizer, LLaMA\n",
    "\n",
    "\n",
    "def load(\n",
    "        ckpt_dir: str,\n",
    "        tokenizer_path: str,\n",
    "        max_seq_len: int,\n",
    "        max_batch_size: int,\n",
    ") -> LLaMA:\n",
    "    print(\"Creating model...\")\n",
    "    start_time = time.time()\n",
    "    checkpoints = sorted(Path(ckpt_dir).glob(\"*.pth\"))\n",
    "\n",
    "    with open(Path(ckpt_dir) / \"params.json\", \"r\") as f:\n",
    "        params = json.loads(f.read())\n",
    "\n",
    "    model_args: ModelArgs = ModelArgs(\n",
    "        max_seq_len=max_seq_len, max_batch_size=max_batch_size, **params\n",
    "    )\n",
    "\n",
    "    tokenizer = Tokenizer(model_path=tokenizer_path)\n",
    "    model_args.vocab_size = tokenizer.n_words\n",
    "\n",
    "#     torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "    model = Transformer(model_args)\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "    # Original copyright by tloen\n",
    "    # https://github.com/tloen/llama-int8/blob/main/example.py\n",
    "    key_to_dim = {\n",
    "        \"w1\": 0,\n",
    "        \"w2\": -1,\n",
    "        \"w3\": 0,\n",
    "        \"wo\": -1,\n",
    "        \"wq\": 0,\n",
    "        \"wk\": 0,\n",
    "        \"wv\": 0,\n",
    "        \"output\": 0,\n",
    "        \"tok_embeddings\": -1,\n",
    "        \"ffn_norm\": None,\n",
    "        \"attention_norm\": None,\n",
    "        \"norm\": None,\n",
    "        \"rope\": None,\n",
    "    }\n",
    "\n",
    "    for i, ckpt in enumerate(checkpoints):\n",
    "        print(f\"Loading checkpoint {i}\")\n",
    "        checkpoint = torch.load(ckpt, map_location=\"cpu\")\n",
    "        for parameter_name, parameter in model.named_parameters():\n",
    "            short_name = parameter_name.split(\".\")[-2]\n",
    "            if key_to_dim[short_name] is None and i == 0:\n",
    "                parameter.data = checkpoint[parameter_name]\n",
    "            elif key_to_dim[short_name] == 0:\n",
    "                size = checkpoint[parameter_name].size(0)\n",
    "                parameter.data[size * i: size * (i + 1), :] = checkpoint[\n",
    "                    parameter_name\n",
    "                ]\n",
    "            elif key_to_dim[short_name] == -1:\n",
    "                size = checkpoint[parameter_name].size(-1)\n",
    "                parameter.data[:, size * i: size * (i + 1)] = checkpoint[\n",
    "                    parameter_name\n",
    "                ]\n",
    "            del checkpoint[parameter_name]\n",
    "        del checkpoint\n",
    "\n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    print(f\"Loaded model in {time.time() - start_time:.2f} seconds\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d14f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Loading checkpoint 0\n",
      "Loaded model in 52.45 seconds\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = '/datasets/llama/7B'\n",
    "tokenizer_path = '/datasets/llama/7B/tokenizer.model'\n",
    "temperature = 0.8\n",
    "top_p = 0.95\n",
    "max_seq_len = 512  # up to 2048\n",
    "max_batch_size = 32\n",
    "\n",
    "model, tokenizer = load(ckpt_dir, tokenizer_path, max_seq_len, max_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c4746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import memory_utils\n",
    "\n",
    "import imp\n",
    "memory_utils = imp.reload(memory_utils)\n",
    "\n",
    "class FlexSequential(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        for module in self._modules.values():\n",
    "            if type(inputs) == tuple:\n",
    "                inputs = module(*inputs)\n",
    "            else:\n",
    "                inputs = module(inputs)\n",
    "        return inputs\n",
    "\n",
    "class LayerToDevice(nn.Module):\n",
    "    def __init__(self, device, layer):\n",
    "        super().__init__()\n",
    "        self.D = device\n",
    "        self.layer = layer\n",
    "    def forward(self, *args):\n",
    "        self.layer.to(self.D)\n",
    "        if(len(args) == 1):\n",
    "            return args[0]\n",
    "        return args\n",
    "    \n",
    "class LayerOffDevice(nn.Module):\n",
    "    def __init__(self, device, layer):\n",
    "        super().__init__()\n",
    "        self.D = device\n",
    "        self.layer = layer\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        self.layer = self.layer.to(memory_utils.cpu_device)\n",
    "        if(len(args) == 1):\n",
    "            return args[0]\n",
    "        return args\n",
    "\n",
    "def move_layer(layer, device): \n",
    "    test =  [LayerToDevice(device, layer)] + [layer] + [LayerOffDevice(device, layer)]\n",
    "    return FlexSequential(*test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a967e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.eval()\n",
    "# base_children = memory_utils.get_base_children(model, max_layer_size = 1e9)\n",
    "\n",
    "# for par, name, module in base_children:\n",
    "#     setattr(par, name, move_layer(module, memory_utils.gpu_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4a803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                      | 0/163 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▊                                                                                                                             | 1/163 [00:07<21:12,  7.85s/it]\u001b[A\n",
      "  1%|█▌                                                                                                                            | 2/163 [00:08<09:20,  3.48s/it]\u001b[A\n",
      "  2%|██▎                                                                                                                           | 3/163 [00:08<05:33,  2.08s/it]\u001b[A\n",
      "  2%|███                                                                                                                           | 4/163 [00:09<03:46,  1.43s/it]\u001b[A\n",
      "  3%|███▊                                                                                                                          | 5/163 [00:09<02:48,  1.07s/it]\u001b[A\n",
      "  4%|████▋                                                                                                                         | 6/163 [00:09<02:12,  1.18it/s]\u001b[A\n",
      "  4%|█████▍                                                                                                                        | 7/163 [00:10<01:50,  1.41it/s]\u001b[A\n",
      "  5%|██████▏                                                                                                                       | 8/163 [00:10<01:35,  1.62it/s]\u001b[A\n",
      "  6%|██████▉                                                                                                                       | 9/163 [00:11<01:25,  1.80it/s]\u001b[A\n",
      "  6%|███████▋                                                                                                                     | 10/163 [00:11<01:18,  1.95it/s]\u001b[A\n",
      "  7%|████████▍                                                                                                                    | 11/163 [00:12<01:13,  2.06it/s]\u001b[A\n",
      "  7%|█████████▏                                                                                                                   | 12/163 [00:12<01:10,  2.15it/s]\u001b[A\n",
      "  8%|█████████▉                                                                                                                   | 13/163 [00:12<01:10,  2.13it/s]\u001b[A\n",
      "  9%|██████████▋                                                                                                                  | 14/163 [00:13<01:08,  2.17it/s]\u001b[A\n",
      "  9%|███████████▌                                                                                                                 | 15/163 [00:13<01:07,  2.20it/s]\u001b[A\n",
      " 10%|████████████▎                                                                                                                | 16/163 [00:14<01:05,  2.24it/s]\u001b[A\n",
      " 10%|█████████████                                                                                                                | 17/163 [00:14<01:04,  2.28it/s]\u001b[A\n",
      " 11%|█████████████▊                                                                                                               | 18/163 [00:15<01:02,  2.31it/s]\u001b[A\n",
      " 12%|██████████████▌                                                                                                              | 19/163 [00:15<01:01,  2.33it/s]\u001b[A\n",
      " 12%|███████████████▎                                                                                                             | 20/163 [00:15<01:01,  2.33it/s]\u001b[A\n",
      " 13%|████████████████                                                                                                             | 21/163 [00:16<01:00,  2.34it/s]\u001b[A\n",
      " 13%|████████████████▊                                                                                                            | 22/163 [00:16<01:00,  2.35it/s]\u001b[A\n",
      " 14%|█████████████████▋                                                                                                           | 23/163 [00:17<00:59,  2.36it/s]\u001b[A\n",
      " 15%|██████████████████▍                                                                                                          | 24/163 [00:17<00:59,  2.35it/s]\u001b[A\n",
      " 15%|███████████████████▏                                                                                                         | 25/163 [00:18<00:58,  2.36it/s]\u001b[A\n",
      " 16%|███████████████████▉                                                                                                         | 26/163 [00:18<00:58,  2.36it/s]\u001b[A\n",
      " 17%|████████████████████▋                                                                                                        | 27/163 [00:18<00:57,  2.36it/s]\u001b[A\n",
      " 17%|█████████████████████▍                                                                                                       | 28/163 [00:19<00:57,  2.36it/s]\u001b[A\n",
      " 18%|██████████████████████▏                                                                                                      | 29/163 [00:19<00:56,  2.36it/s]\u001b[A\n",
      " 18%|███████████████████████                                                                                                      | 30/163 [00:20<00:56,  2.36it/s]\u001b[A\n",
      " 19%|███████████████████████▊                                                                                                     | 31/163 [00:20<00:55,  2.36it/s]\u001b[A\n",
      " 20%|████████████████████████▌                                                                                                    | 32/163 [00:21<00:55,  2.36it/s]\u001b[A\n",
      " 20%|█████████████████████████▎                                                                                                   | 33/163 [00:21<00:55,  2.36it/s]\u001b[A\n",
      " 21%|██████████████████████████                                                                                                   | 34/163 [00:21<00:54,  2.36it/s]\u001b[A\n",
      " 21%|██████████████████████████▊                                                                                                  | 35/163 [00:22<00:54,  2.35it/s]\u001b[A\n",
      " 22%|███████████████████████████▌                                                                                                 | 36/163 [00:22<00:54,  2.35it/s]\u001b[A\n",
      " 23%|████████████████████████████▎                                                                                                | 37/163 [00:23<00:53,  2.36it/s]\u001b[A\n",
      " 23%|█████████████████████████████▏                                                                                               | 38/163 [00:23<00:53,  2.34it/s]\u001b[A\n",
      " 24%|█████████████████████████████▉                                                                                               | 39/163 [00:24<00:52,  2.35it/s]\u001b[A\n",
      " 25%|██████████████████████████████▋                                                                                              | 40/163 [00:24<00:52,  2.35it/s]\u001b[A\n",
      " 25%|███████████████████████████████▍                                                                                             | 41/163 [00:24<00:51,  2.35it/s]\u001b[A\n",
      " 26%|████████████████████████████████▏                                                                                            | 42/163 [00:25<00:51,  2.35it/s]\u001b[A\n",
      " 26%|████████████████████████████████▉                                                                                            | 43/163 [00:25<00:50,  2.36it/s]\u001b[A\n",
      " 27%|█████████████████████████████████▋                                                                                           | 44/163 [00:26<00:54,  2.18it/s]\u001b[A\n",
      " 28%|██████████████████████████████████▌                                                                                          | 45/163 [00:26<01:03,  1.85it/s]\u001b[A\n",
      " 28%|███████████████████████████████████▎                                                                                         | 46/163 [00:27<01:07,  1.74it/s]\u001b[A\n",
      " 29%|████████████████████████████████████                                                                                         | 47/163 [00:28<01:07,  1.73it/s]\u001b[A\n",
      " 29%|████████████████████████████████████▊                                                                                        | 48/163 [00:28<01:06,  1.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████████████▌                                                                                       | 49/163 [00:29<01:00,  1.88it/s]\u001b[A\n",
      " 31%|██████████████████████████████████████▎                                                                                      | 50/163 [00:29<00:56,  1.99it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████                                                                                      | 51/163 [00:30<00:53,  2.09it/s]\u001b[A\n",
      " 32%|███████████████████████████████████████▉                                                                                     | 52/163 [00:30<00:51,  2.17it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████▋                                                                                    | 53/163 [00:30<00:49,  2.23it/s]\u001b[A\n",
      " 33%|█████████████████████████████████████████▍                                                                                   | 54/163 [00:31<00:48,  2.27it/s]\u001b[A\n",
      " 34%|██████████████████████████████████████████▏                                                                                  | 55/163 [00:31<00:47,  2.29it/s]\u001b[A\n",
      " 34%|██████████████████████████████████████████▉                                                                                  | 56/163 [00:32<00:46,  2.32it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████▋                                                                                 | 57/163 [00:32<00:45,  2.33it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████▍                                                                                | 58/163 [00:33<00:44,  2.34it/s]\u001b[A\n",
      " 36%|█████████████████████████████████████████████▏                                                                               | 59/163 [00:33<00:44,  2.34it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████                                                                               | 60/163 [00:33<00:43,  2.35it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████▊                                                                              | 61/163 [00:34<00:43,  2.36it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████▌                                                                             | 62/163 [00:34<00:42,  2.36it/s]\u001b[A\n",
      " 39%|████████████████████████████████████████████████▎                                                                            | 63/163 [00:35<00:42,  2.36it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████                                                                            | 64/163 [00:35<00:41,  2.36it/s]\u001b[A\n",
      " 40%|█████████████████████████████████████████████████▊                                                                           | 65/163 [00:36<00:41,  2.36it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████▌                                                                          | 66/163 [00:36<00:40,  2.37it/s]\u001b[A\n",
      " 41%|███████████████████████████████████████████████████▍                                                                         | 67/163 [00:36<00:40,  2.36it/s]\u001b[A\n",
      " 42%|████████████████████████████████████████████████████▏                                                                        | 68/163 [00:37<00:40,  2.37it/s]\u001b[A\n",
      " 42%|████████████████████████████████████████████████████▉                                                                        | 69/163 [00:37<00:39,  2.36it/s]\u001b[A\n",
      " 43%|█████████████████████████████████████████████████████▋                                                                       | 70/163 [00:38<00:39,  2.37it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████▍                                                                      | 71/163 [00:38<00:38,  2.37it/s]\u001b[A\n",
      " 44%|███████████████████████████████████████████████████████▏                                                                     | 72/163 [00:38<00:38,  2.36it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████▉                                                                     | 73/163 [00:39<00:38,  2.36it/s]\u001b[A\n",
      " 45%|████████████████████████████████████████████████████████▋                                                                    | 74/163 [00:39<00:37,  2.36it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████▌                                                                   | 75/163 [00:40<00:37,  2.36it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████▎                                                                  | 76/163 [00:40<00:36,  2.35it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████                                                                  | 77/163 [00:41<00:36,  2.36it/s]\u001b[A\n",
      " 48%|███████████████████████████████████████████████████████████▊                                                                 | 78/163 [00:41<00:35,  2.36it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████▌                                                                | 79/163 [00:41<00:35,  2.36it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████▎                                                               | 80/163 [00:42<00:35,  2.36it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████                                                               | 81/163 [00:42<00:35,  2.33it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████▉                                                              | 82/163 [00:43<00:34,  2.33it/s]\u001b[A\n",
      " 51%|███████████████████████████████████████████████████████████████▋                                                             | 83/163 [00:43<00:34,  2.34it/s]\u001b[A\n",
      " 52%|████████████████████████████████████████████████████████████████▍                                                            | 84/163 [00:44<00:33,  2.35it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████████████████████████████▏                                                           | 85/163 [00:44<00:33,  2.35it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████▉                                                           | 86/163 [00:44<00:32,  2.34it/s]\u001b[A\n",
      " 53%|██████████████████████████████████████████████████████████████████▋                                                          | 87/163 [00:45<00:32,  2.35it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████▍                                                         | 88/163 [00:45<00:31,  2.35it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████▎                                                        | 89/163 [00:46<00:31,  2.35it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████████████████████████████████                                                        | 90/163 [00:46<00:30,  2.36it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████████████▊                                                       | 91/163 [00:47<00:30,  2.36it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████▌                                                      | 92/163 [00:47<00:30,  2.36it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████▎                                                     | 93/163 [00:47<00:29,  2.36it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████                                                     | 94/163 [00:48<00:29,  2.36it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████▊                                                    | 95/163 [00:48<00:28,  2.36it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████████████████████████████████▌                                                   | 96/163 [00:49<00:28,  2.35it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████████████████████████████▍                                                  | 97/163 [00:49<00:28,  2.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████████▏                                                 | 98/163 [00:50<00:27,  2.35it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████████████████████████████████████▉                                                 | 99/163 [00:50<00:27,  2.36it/s]\u001b[A\n",
      " 61%|████████████████████████████████████████████████████████████████████████████                                                | 100/163 [00:50<00:26,  2.36it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████▊                                               | 101/163 [00:51<00:26,  2.36it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████▌                                              | 102/163 [00:51<00:25,  2.36it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████▎                                             | 103/163 [00:52<00:25,  2.35it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████                                             | 104/163 [00:52<00:25,  2.35it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████▉                                            | 105/163 [00:52<00:24,  2.36it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████▋                                           | 106/163 [00:53<00:24,  2.36it/s]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████████████████████████████████████▍                                          | 107/163 [00:53<00:23,  2.36it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████▏                                         | 108/163 [00:54<00:23,  2.36it/s]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████▉                                         | 109/163 [00:54<00:22,  2.36it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████▋                                        | 110/163 [00:55<00:22,  2.36it/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████████████████████████████████████████▍                                       | 111/163 [00:55<00:22,  2.36it/s]\u001b[A\n",
      " 69%|█████████████████████████████████████████████████████████████████████████████████████▏                                      | 112/163 [00:55<00:21,  2.36it/s]\u001b[A\n",
      " 69%|█████████████████████████████████████████████████████████████████████████████████████▉                                      | 113/163 [00:56<00:21,  2.36it/s]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████▋                                     | 114/163 [00:56<00:20,  2.36it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████▍                                    | 115/163 [00:57<00:20,  2.36it/s]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████▏                                   | 116/163 [00:57<00:19,  2.36it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████                                   | 117/163 [00:58<00:19,  2.35it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████▊                                  | 118/163 [00:58<00:19,  2.35it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████▌                                 | 119/163 [00:58<00:18,  2.36it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████▎                                | 120/163 [00:59<00:18,  2.36it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████                                | 121/163 [00:59<00:17,  2.36it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████▊                               | 122/163 [01:00<00:17,  2.35it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████▌                              | 123/163 [01:00<00:16,  2.36it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████▎                             | 124/163 [01:01<00:16,  2.36it/s]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████                             | 125/163 [01:01<00:16,  2.36it/s]\u001b[A\n",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████▊                            | 126/163 [01:01<00:15,  2.36it/s]\u001b[A\n",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 127/163 [01:02<00:15,  2.36it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 128/163 [01:02<00:14,  2.36it/s]\u001b[A\n",
      " 79%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 129/163 [01:03<00:14,  2.33it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 130/163 [01:03<00:14,  2.34it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 131/163 [01:04<00:13,  2.35it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 132/163 [01:04<00:13,  2.34it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 133/163 [01:04<00:12,  2.35it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 134/163 [01:05<00:12,  2.34it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 135/163 [01:05<00:11,  2.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 136/163 [01:06<00:11,  2.35it/s]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                   | 137/163 [01:06<00:11,  2.35it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 138/163 [01:07<00:10,  2.35it/s]\u001b[A\n",
      " 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 139/163 [01:07<00:10,  2.35it/s]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 140/163 [01:07<00:09,  2.35it/s]\u001b[A\n",
      " 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 141/163 [01:08<00:09,  2.35it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 142/163 [01:08<00:08,  2.35it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 143/163 [01:09<00:08,  2.35it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 144/163 [01:09<00:08,  2.35it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 145/163 [01:09<00:07,  2.35it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 146/163 [01:10<00:07,  2.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 147/163 [01:10<00:06,  2.35it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 148/163 [01:11<00:06,  2.35it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 149/163 [01:11<00:05,  2.35it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 150/163 [01:12<00:05,  2.34it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 151/163 [01:12<00:05,  2.34it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 152/163 [01:12<00:04,  2.32it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 153/163 [01:13<00:04,  2.30it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 154/163 [01:13<00:03,  2.31it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 155/163 [01:14<00:03,  2.32it/s]\u001b[A\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 156/163 [01:14<00:03,  2.33it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "generator = LLaMA(model, tokenizer)\n",
    "\n",
    "prompts = [\n",
    "    \"\"\"\n",
    "    The standard models have their weights (the connections between the NN) stored as floating points. This makes the models very large and difficult to store in either system or GPU RAM. Also, CPU’s are just not good at doing floating point math compared to GPU’s. Though, there are ways to improve your performance on CPU, namely by understanding how different converted models work.\n",
    "\n",
    "This is where quantized models come into play. There’s 8-bit quantized models that use methods like zero-point quantization to change the model from floating point weights to 8-bit integers. This can run on a wider array of hardware, especially 7 billion or 13 billion parameter models. Though, there’s ways to even further reduce the hardware needs.\n",
    "\n",
    "We also have GPTQ 4-bit quantizing (there are also 3 and 2-bit methods, but I’m not familiar with them, personally). This will let you easily run the 13 billion parameter model on consumer hardware. But what kind of hardware? CPU or GPU?\n",
    "\n",
    "This is where GGML comes in. If you want to use a CPU, you would want to run a GGML optimized version, this will let you leverage a CPU and system RAM. I’ve seen some people saying 1 or 2 tokens per second, I imagine they are NOT running GGML versions. If you plan to run this on a GPU, you would want to use a standard GPTQ 4-bit quantized model.\n",
    "\n",
    "I hope this helps demystify a bit of what different configurations do for different hardware. \n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "results = generator.generate(\n",
    "    prompts, max_gen_len=256, temperature=temperature, top_p=top_p, on_cpu=True\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f34fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = nn.Sequential()\n",
    "base2 = move_layer(base, torch.device('cpu'))\n",
    "#ltd = LayerToDevice(torch.device('cpu'), nn.Sequential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3988462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): FlexSequential(\n",
       "    (0): LayerToDevice(\n",
       "      (layer): Embedding(32000, 4096)\n",
       "    )\n",
       "    (1): Embedding(32000, 4096)\n",
       "    (2): LayerOffDevice(\n",
       "      (layer): Embedding(32000, 4096)\n",
       "    )\n",
       "  )\n",
       "  (layers): FlexSequential(\n",
       "    (0): LayerToDevice(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (6): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (7): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (8): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (9): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (10): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (11): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (12): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (13): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (14): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (15): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (16): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (17): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (18): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (19): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (20): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (21): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (22): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (23): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (24): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (25): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (26): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (27): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (28): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (29): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (30): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (31): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (6): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (7): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (8): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (9): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (10): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (11): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (12): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (13): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (14): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (15): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (16): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (17): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (18): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (19): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (20): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (21): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (22): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (23): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (24): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (25): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (26): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (27): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (28): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (29): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (30): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "      (31): TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (2): LayerOffDevice(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (6): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (7): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (8): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (9): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (10): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (11): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (12): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (13): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (14): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (15): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (16): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (17): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (18): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (19): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (20): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (21): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (22): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (23): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (24): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (25): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (26): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (27): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (28): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (29): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (30): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "        (31): TransformerBlock(\n",
       "          (attention): Attention(\n",
       "            (wq): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (wo): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (feed_forward): FeedForward(\n",
       "            (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (w2): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (w3): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          )\n",
       "          (attention_norm): RMSNorm()\n",
       "          (ffn_norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): FlexSequential(\n",
       "    (0): LayerToDevice(\n",
       "      (layer): RMSNorm()\n",
       "    )\n",
       "    (1): RMSNorm()\n",
       "    (2): LayerOffDevice(\n",
       "      (layer): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (output): FlexSequential(\n",
       "    (0): LayerToDevice(\n",
       "      (layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "    (1): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    (2): LayerOffDevice(\n",
       "      (layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609348b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.layers[0].layer) == tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f9bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99cc6692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "295f4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a45b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
